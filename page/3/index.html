<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="nlp"><meta name="keywords" content=""><meta name="author" content="zhxnlp"><meta name="copyright" content="zhxnlp"><title>You got a dream, you gotta protect it | zhxnlpのBlog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"JU6VFRRZVF","apiKey":"ca17f8e20c4dc91dfe1214d03173a8be","indexName":"github-io","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '6.0.0'
} </script><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="zhxnlpのBlog" type="application/atom+xml">
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="https://img-blog.csdnimg.cn/92202ef591744a55a05a1fc7e108f4d6.png"></div><div class="author-info__name text-center">zhxnlp</div><div class="author-info__description text-center">nlp</div><div class="follow-button"><a target="_blank" rel="noopener" href="https://github.com/zhxnlp">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">58</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">50</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">10</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://relph1119.github.io/my-team-learning">relph</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://ifwind.github.io/">ifwind</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://chuxiaoyu.cn/nlp-transformer-summary/">chuxiaoyu</a></div></div></div><nav id="nav" style="background-image: url(https://img-blog.csdnimg.cn/ffe1f736be4548dc9101388503288e4d.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">zhxnlpのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="site-info"><div id="site-title">zhxnlpのBlog</div><div id="site-sub-title">You got a dream, you gotta protect it</div><div id="site-social-icons"><a class="social-icon" href="https://github.com/zhxnlp/nlp-transformers" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-github fa"></i></a><a class="social-icon" href="https://gitee.com/zhxscut" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-google fa"></i></a><a class="social-icon" href="https://blog.csdn.net/qq_56591814" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-weibo fa"></i></a></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2021/12/02/datawhale%E8%AF%BE%E7%A8%8B%E2%80%94%E2%80%94%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A01%E2%80%94%E2%80%94voting%E3%80%81bagging&amp;stacking/">集成学习1——voting、bagging&amp;stacking</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-12-02</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">集成学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">集成学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/bagging/">bagging</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/stacking/">stacking</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/">随机森林</a></span><div class="content"><blockquote>
<p>参考datawhale课程<a target="_blank" rel="noopener" href="https://github.com/datawhalechina/ensemble-learning">《集成学习》</a><br>参考<a target="_blank" rel="noopener" href="https://www.cnblogs.com/Christina-Notebook/p/10063146.html">《Stacking方法详解》</a></p>
</blockquote>
<p>Bagging思想的实质是：通过Bootstrap 的方式对全样本数据集进行抽样得到抽样子集，对不同的子集使用同一种基本模型进行拟合，然后投票得出最终的预测。Bagging主要通过降低方差的方式减少预测误差</p>
<h2 id="一、投票法与bagging"><a href="#一、投票法与bagging" class="headerlink" title="一、投票法与bagging"></a>一、投票法与bagging</h2><h3 id="1-1-投票法的原理分析"><a href="#1-1-投票法的原理分析" class="headerlink" title="1.1 投票法的原理分析"></a>1.1 投票法的原理分析</h3><p>投票法是一种遵循少数服从多数原则的集成学习模型，通过多个模型的集成降低方差，从而提高模型的鲁棒性。在理想情况下，投票法的预测效果应当优于任何一个基模型的预测效果。</p>
<ul>
<li>回归投票法：预测结果是所有模型预测结果的平均值。</li>
<li>分类投票法：预测结果是所有模型种出现最多的预测结果。</li>
</ul>
<p>分类投票法又可以被划分为硬投票与软投票：</p>
<ul>
<li>硬投票：预测结果是所有投票结果最多出现的类。（基模型能预测出清晰的类别标签时）</li>
<li>软投票：预测结果是所有投票结果中概率加和最大的类。（基模型能预测类别的概率，或可以输出类似于概率的预测分数值，例如支持向量机、k-最近邻和决策树等）</div><a class="more" href="/2021/12/02/datawhale%E8%AF%BE%E7%A8%8B%E2%80%94%E2%80%94%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A01%E2%80%94%E2%80%94voting%E3%80%81bagging&amp;stacking/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2021/11/30/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">学习笔记7：循环神经网络</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-11-30</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/LSTM/">LSTM</a></span><div class="content"><h2 id="一、RNN"><a href="#一、RNN" class="headerlink" title="一、RNN"></a>一、RNN</h2><p>前馈神经网络：信息往一个方向流动。包括MLP和CNN<br>循环神经网络：信息循环流动，网络隐含层输出又作为自身输入&lt;/font&gt;，包括RNN、LSTM、GAN等。</p>
<h3 id="1-1-RNN模型结构"><a href="#1-1-RNN模型结构" class="headerlink" title="1.1 RNN模型结构"></a>1.1 RNN模型结构</h3><p>RNN模型结构如下图所示：<br><img src="https://img-blog.csdnimg.cn/62ffdeb2b9ec4e2cbcd4edfc85583c24.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6K-75Lmm5LiN6KeJ5bey5pil5rex77yB,size_9,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<p>展开之后相当于堆叠多个共享隐含层参数的前馈神经网络：<br><img src="https://img-blog.csdnimg.cn/e43dbda3e0d24019a13285a6e31086c4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6K-75Lmm5LiN6KeJ5bey5pil5rex77yB,size_18,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></div><a class="more" href="/2021/11/30/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%EF%BC%9A%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2021/11/27/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)/">学习笔记6：卷积神经网络CNN</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-11-27</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/CNN/">CNN</a></span><div class="content"><h2 id="一、CNN模型原理"><a href="#一、CNN模型原理" class="headerlink" title="一、CNN模型原理"></a>一、CNN模型原理</h2><h3 id="1-1-图像"><a href="#1-1-图像" class="headerlink" title="1.1 图像"></a>1.1 图像</h3><ul>
<li>图像具有平移不变性和旋转不变性。即对图像的平移或者轻微旋转不改变其类别。图像可以用像素点来表示，存储为一个三维矩阵（长×宽×channels）</li>
<li>黑白图片channels=1，即每个像素点只有灰度值。彩色图像channels=3，每个像素点由RGB三原色组成，对应一个三维向量，值域[0，255]。一般0表示白色，255表示黑色<h3 id="1-2-DNN图像分类的问题"><a href="#1-2-DNN图像分类的问题" class="headerlink" title="1.2 DNN图像分类的问题"></a>1.2 DNN图像分类的问题</h3>如果直接将图像根据各像素点的向量作为图片特征输入模型，例如LR、SVM、DNN等模型进行分类，理论上可行，但是面临以下问题：</li>
<li>图像的平移旋转、手写数字笔迹的变化等，会造成输入图像特征矩阵的剧烈变化，影响分类结果。即不抗平移旋转等。</li>
<li>一般图像像素很高，如果直接DNN这样全连接处理，计算量太大，耗时太长；参数太多需要大量训练样本</div><a class="more" href="/2021/11/27/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%EF%BC%9A%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2021/11/27/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9Aword2vec%E5%92%8Cfasttext/">学习笔记5：word2vec、FastText原理</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-11-27</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/DNN/">DNN</a></span><div class="content"><h2 id="一、word2vec"><a href="#一、word2vec" class="headerlink" title="一、word2vec"></a>一、word2vec</h2><p>参考文档<a target="_blank" rel="noopener" href="https://maxiang.io/note/#%E4%B8%80-cbow%E4%B8%8Eskip-gram%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80">《word2vec原理和gensim实现》</a>、<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/114538417">《深入浅出Word2Vec原理解析》</a></p>
<h3 id="1-1-word2vec为什么-不用现成的DNN模型"><a href="#1-1-word2vec为什么-不用现成的DNN模型" class="headerlink" title="1.1 word2vec为什么 不用现成的DNN模型"></a>1.1 word2vec为什么 不用现成的DNN模型</h3><ol>
<li>最主要的问题是DNN模型的这个处理过程非常耗时。我们的词汇表一般在百万级别以上，==从隐藏层到输出的softmax层的计算量很大，因为要计算所有词的softmax概率，再去找概率最大的值==。解决办法有两个：霍夫曼树和负采样。</li>
<li>对于从输入层到隐藏层的映射，没有采取神经网络的线性变换加激活函数的方法，而是采用简单的对所有输入词向量求和并取平均的方法。输入从多个词向量变成了一个词向量</li>
<li>在word2vec中，由于使用的是随机梯度上升法，所以并没有把所有样本的似然乘起来得到真正的训练集最大似然，仅仅每次只用一个样本更新梯度，这样做的目的是减少梯度计算量</div><a class="more" href="/2021/11/27/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%EF%BC%9Aword2vec%E5%92%8Cfasttext/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2021/11/25/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0DNN2/">学习笔记4：深度学习DNN2</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-11-25</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/DNN/">DNN</a></span><div class="content"><h2 id="一、神经网络参数优化器"><a href="#一、神经网络参数优化器" class="headerlink" title="一、神经网络参数优化器"></a>一、神经网络参数优化器</h2><p>参考曹健<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45558569/article/details/110728137?spm=1001.2014.3001.5501">《人工智能实践：Tensorflow2.0 》</a><br>深度学习优化算法经历了SGD -&gt; SGDM -&gt; NAG -&gt;AdaGrad -&gt; AdaDelta -&gt; Adam -&gt; Nadam<br>这样的发展历程。<br><img src="https://img-blog.csdnimg.cn/65f1bb4bf04f4aa8b260f2126b37099a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6K-75Lmm5LiN6KeJ5bey5pil5rex77yB,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br></div><a class="more" href="/2021/11/25/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0DNN2/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2021/11/23/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0DNN/">学习笔记3：深度学习DNN</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-11-23</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/DNN/">DNN</a></span><div class="content"><h2 id="一、BP神经网络"><a href="#一、BP神经网络" class="headerlink" title="一、BP神经网络"></a>一、BP神经网络</h2><h3 id="1-1-为何要引出BP神经网络"><a href="#1-1-为何要引出BP神经网络" class="headerlink" title="1.1 为何要引出BP神经网络"></a>1.1 为何要引出BP神经网络</h3><ol>
<li>逻辑回归对于如今越来越复杂的任务效果越来越差，主要是难以处理线性不可分的数据，LR处理线性不可分，一般是特征变换和特征组合，将低维空间线性不可分的数据在高维空间中线性可分</li>
<li>改良方式有几种，本质上都是对原始输入特征做文章。但都是针对特定场景设计。如果实际场景中特征组合在设计之外，模型无能为力<ul>
<li>人工组合高维特征，将特征升维至高维空间。但是会耗费较多人力，而且需要对业务理解很深</li>
<li>自动交叉二阶特征，例如FM模型。缺点是只能进行二阶交叉</li>
<li>SVM+核方法：可以将特征投影到高维空间。缺点是核函数种类有限，升维具有局限性，运算量巨大。</div><a class="more" href="/2021/11/23/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0DNN/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2021/11/22/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81%E5%86%B3%E7%AD%96%E6%A0%91%E3%80%81%E8%81%9A%E7%B1%BB/">学习笔记2：线性回归、决策树、聚类</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-11-22</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E8%81%9A%E7%B1%BB/">聚类</a></span><div class="content"><h2 id="学习笔记2——线性回归、决策树、聚类"><a href="#学习笔记2——线性回归、决策树、聚类" class="headerlink" title="学习笔记2——线性回归、决策树、聚类"></a>学习笔记2——线性回归、决策树、聚类</h2><h2 id="一、-线性回归"><a href="#一、-线性回归" class="headerlink" title="一、.线性回归"></a>一、.线性回归</h2><pre><code>fit_intercept : 布尔型参数，表示是否计算该模型截距。可选参数。
normalize : 布尔型参数，若为True，则X在回归前进行归一化。可选参数。默认值为False。
copy_X : 布尔型参数，若为True，则X将被复制；否则将被覆盖。 可选参数。默认值为True。
n_jobs : 整型参数，表示用于计算的作业数量；若为-1，则用所有的CPU。可选参数。默认为1
positive=False#当设置为&#39;True&#39;时，强制系数为正。这选项仅支持密集阵列。

rint(model.coef_)#打印线性方程中的w
print(model.intercept_)#打印w0 就是线性方程中的截距b
</code></pre></div><a class="more" href="/2021/11/22/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81%E5%86%B3%E7%AD%96%E6%A0%91%E3%80%81%E8%81%9A%E7%B1%BB/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2021/11/18/10%E6%9C%88%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Pytorch/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%EF%BC%9Ann.Module%E3%80%81%E4%BC%98%E5%8C%96%E5%99%A8%E3%80%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E3%80%81TensorBoard/">PyTorch学习笔记2：nn.Module、优化器、模型的保存和加载、TensorBoard</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-11-18</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/10%E6%9C%88%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0%EF%BC%9APytorch/">10月组队学习：Pytorch</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Pytorch/">Pytorch</a></span><div class="content"><p>@[toc]<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/265394674">《PyTorch 学习笔记汇总（完结撒花）》</a></p>
<h2 id="一、nn-Module"><a href="#一、nn-Module" class="headerlink" title="一、nn.Module"></a>一、nn.Module</h2><h3 id="1-1-nn-Module的调用"><a href="#1-1-nn-Module的调用" class="headerlink" title="1.1 nn.Module的调用"></a>1.1 nn.Module的调用</h3><p>pytorch通过继承nn.Module类，定义子模块的实例化和前向传播，实现深度学习模型的搭建。其构建代码如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *kargs</span>):</span> <span class="comment"># 定义类的初始化函数，...是用户的传入参数</span></span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()<span class="comment">#调用父类nn.Module的初始化方法</span></span><br><span class="line">        ... <span class="comment"># 根据传入的参数来定义子模块</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, *kargs</span>):</span> <span class="comment"># 定义前向计算的输入参数，...一般是张量或者其他的参数</span></span><br><span class="line">        ret = ... <span class="comment"># 根据传入的张量和子模块计算返回张量</span></span><br><span class="line">        <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>init\</strong>方法初始化整个模型</li>
<li>super(Model, self).<strong>init\</strong>():调用父类nn.Module的初始化方法，初始化必要的变量和参数</li>
<li>定义前向传播模块</li>
</ul></div><a class="more" href="/2021/11/18/10%E6%9C%88%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Pytorch/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%EF%BC%9Ann.Module%E3%80%81%E4%BC%98%E5%8C%96%E5%99%A8%E3%80%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD%E3%80%81TensorBoard/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2021/11/17/10%E6%9C%88%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Pytorch/python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1%E3%80%81%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/">python类与对象</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-11-17</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/10%E6%9C%88%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0%EF%BC%9APytorch/">10月组队学习：Pytorch</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/python/">python</a></span><div class="content"><p>@[toc]</p>
<h2 id="一、python的类与对象"><a href="#一、python的类与对象" class="headerlink" title="一、python的类与对象"></a>一、python的类与对象</h2><p>参考<a target="_blank" rel="noopener" href="https://github.com/datawhalechina/team-learning-program/blob/master/PythonLanguage/13.%20%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1.md">《datawhale——PythonLanguage》</a>、<a target="_blank" rel="noopener" href="https://www.runoob.com/python3/python3-class.html">《Python3 面向对象》</a></p>
<h3 id="1-1-基本概念"><a href="#1-1-基本概念" class="headerlink" title="1.1 基本概念"></a>1.1 基本概念</h3><p>对象 = 属性 + 方法<br>对象是类的实例。换句话说，类主要定义对象的结构，然后我们以类为模板创建对象。类不但包含方法定义，而且还包含所有实例共享的数据</p>
<ul>
<li>类(Class): 用来描述具有相同的属性和方法的对象的集合。它定义了该集合中每个对象所共有的属性和方法。对象是类的实例。</li>
<li>对象：通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。</li>
<li>方法：类中定义的函数&lt;/font&gt;。</li>
<li>类属性：类里面方法外面定义的变量称为类属性。&lt;/font&gt;类属性所属于类对象并且多个实例对象之间共享同一个类属性，说白了就是类属性所有的通过该类实例化的对象都能共享。</li>
</ul></div><a class="more" href="/2021/11/17/10%E6%9C%88%E7%BB%84%E9%98%9F%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Pytorch/python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1%E3%80%81%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/#more">阅读更多</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2021/11/15/CLUENER%20%E7%BB%86%E7%B2%92%E5%BA%A6%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/bert_lstm_crf/">命名实体识别——bert_lstm_crf模型</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-11-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/CLUENER-%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/">CLUENER 命名实体识别</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/nlp/">nlp</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/NER/">NER</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/CRF/">CRF</a></span><div class="content"><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">&#x27;/content/drive&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&quot;/content/drive&quot;, force_remount=True).
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(<span class="string">&#x27;/content/drive/MyDrive/chinese task/CLUENER2020&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装</span></span><br><span class="line">!pip install transformers datasets pytorch-crf seqeval</span><br></pre></td></tr></table></figure></div><a class="more" href="/2021/11/15/CLUENER%20%E7%BB%86%E7%B2%92%E5%BA%A6%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/bert_lstm_crf/#more">阅读更多</a><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://img-blog.csdnimg.cn/ffe1f736be4548dc9101388503288e4d.png)"><div class="layout" id="footer"><div class="copyright">&copy;2021 - 2023 By zhxnlp</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script src="/js/search/algolia.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>